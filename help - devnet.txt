Certification 350-901 DEVCOR
----------------------------
Developing Applications using Cisco Core Platforms and APIs v1.0 (350-901)
Developing Applications using Cisco Core Platforms and APIs v1.0 (DEVCOR 350-901) is a 120-minute exam associated with the DevNet Professional Certification. This exam tests a candidate's knowledge of software development and design including using APIs, Cisco platforms, application deployment and security, and infrastructure and automation. The course, Developing Applications using Cisco Core Platforms and APIs helps candidates to prepare for this exam.

Exam overview
1.0 Software Development and Design
1.1 Describe distributed applications related to the concepts of front-end, back-end, and load balancing
1.2 Evaluate an application design considering scalability and modularity
1.3 Evaluate an application design considering high-availability and resiliency (including on-premises, hybrid, and cloud)
1.4 Evaluate an application design considering latency and rate limiting
1.5 Evaluate an application design and implementation considering maintainability
1.6 Evaluate an application design and implementation considering observability
1.7 Diagnose problems with an application given logs related to an event
1.8 Evaluate choice of database types with respect to application requirements (such as relational, document, graph, columnar, and Time Series)
1.9 Explain architectural patterns (monolithic, services oriented, microservices, and event driven)
1.10 Utilize advanced version control operations with Git
1.10.a Merge a branch
1.10.b Resolve conflicts
1.10.c git reset
1.10.d git checkout
1.10.e git revert
1.11 Explain the concepts of release packaging and dependency management
1.12 Construct a sequence diagram that includes API calls

Study Material
Setting up your Linux (Ubuntu) workstation as a development environment
Setting up your Windows workstation as a development environment
Setting up your macOS workstation as a development environment
What is a Development Environment and why do you need one?
A brief introduction to Git
Intro to Python Part 1
Intro to Python Part 2
Coding 202: Parsing JSON using Python
Introduction to XML
Introduction to the Guest Shell
Chat-Ops with Webex Teams and Python
Firepower Management Center (FMC) REST API token-based authentication
Exploring the 'webexteamssdk' Webex Teams Python Library
Git 100: Basics of the git version control system
Git 101: Branching
Git 102: Using git with servers
Introduction to Webex Teams Apps
Modern Application Development
Modern Application Development
Understanding the OAuth Flow of a Webex Teams Integration
Webex Teams Security and Access: Tokens, OAuth, Scopes, and Roles


Exam overview
2.0 Using APIs
2.1 Implement robust REST API error handling for time outs and rate limits
2.2 Implement control flow of consumer code for unrecoverable REST API errors
2.3 Identify ways to optimize API usage through HTTP cache controls
2.4 Construct an application that consumes a REST API that supports pagination
2.5 Describe the steps in the OAuth2 three-legged authorization code grant flow

Study Material
What is REST? What are APIs
Intro to Coding and APIs
Getting started with REST APIs
Hands On: Use Postman to interact with REST APIs
Prime Infrastructure API 101: REST Basics
Invoke Webex REST APIs from the interactive documentation
Building Python Requests to Read and Create Webex Teams API Items
Introduction to XML
Introductory UCS Director REST API, Custom Tasks and Workflow Creation Part I
Meraki Dashboard API Using Postman
Meraki Location Scanning API Python
Run a Webex Teams Bot Locally


Exam overview
3.0 Cisco Platforms
3.1 Construct API requests to implement chatops with Webex Teams API
3.2 Construct API requests to create and delete objects using Firepower device management (FDM)
3.3 Construct API requests using the Meraki platform to accomplish these tasks
3.3.a Use Meraki Dashboard APIs to enable an SSID
3.3.b Use Meraki location APIs to retrieve location data

Study Material
Exploring Firepower Management Center (FMC) REST APIs
Introduction to Meraki Integrations
Introduction to Cisco DNA Center Northbound APIs
Cisco DNA Center API Overview
Cisco DNA Center Northbound API Modules
What and Why of Model Driven Programmability
Introducing YANG Data Modeling for the Network


Exam overview
4.0 Application Deployment and Security
4.1 Diagnose a CI/CD pipeline failure (such as missing dependency, incompatible versions of components, and failed tests)
4.2 Integrate an application into a prebuilt CD environment leveraging Docker and Kubernetes
4.3 Describe the benefits of continuous testing and static code analysis in a CI pipeline
4.4 Utilize Docker to containerize an application
4.5 Describe the tenets of the "12-factor app"
4.6 Describe an effective logging strategy for an application
4.7 Explain data privacy concerns related to storage and transmission of data
4.8 Identify the secret storage approach relevant to a given scenario
4.9 Configure application specific SSL certificates
4.10 Implement mitigation strategies for OWASP threats (such as XSS, CSRF, and SQL injection)
4.11 Describe how end-to-end encryption principles apply to APIs

Study Material
Introducing Containers
Docker 101
Microservices overview


Exam overview
5.0 Infrastructure and Automation
5.1 Explain considerations of model-driven telemetry (including data consumption and data storage)
5.2 Utilize RESTCONF to configure a network device including interfaces, static routes, and VLANs (IOS XE only)
5.3 Construct a workflow to configure network parameters with:
5.3.a Ansible playbook
5.3.b Puppet manifest
5.4 Identify a configuration management solution to achieve technical and business requirements
5.5 Describe how to host an application on a network device (including Catalyst 9000 and Cisco IOx-enabled devices)

Study Material
Introduction to Meraki integrations
Using the Meraki Dashboard API with postman
Meraki location scanning API Python
A hands-on introduction to the Cisco Container Platform v3.1
Advanced Docker features
Building an IOx Application with Docker
Introduction to Ansible
Managing Cisco Compute with Ansible
Microservices overview


-------------------------------


Modular software design enforces the following software qualities:
- Composability
- Decomposability
- Understandability
- Continuity
- Protection

SOLID:
- Single Responsibility Principle (SRP)
- Open-Closed Principle (OCP)
- Liskov's Substitution Principle (LSP)
- Interface Segregation Principle (ISP)
- Dependency Inversion Principle (DIP)

Dependency injection methods:
- Constructor injection
- Setter injection
- Interface injection

Dependency injection roles:
- Service
- Client (uses the service)
- Interface
- Injector (constructs service and injects into client)


Observability in Application Design:
- Logging
- Monitoring
- Documentation


Logging levels (subset of DINWECAE):
- INFO
- WARNING
- ERROR
- CRITICAL (FATAL)

- OFF/NOTSET
- TRACE
- ALL

DINWECAE Logging levels:
0 — emergency: System unusable
1 — alert: Immediate action needed
2 — critical: Critical condition—default level
3 — error: Error condition
4 — warning: Warning condition
5 — notification: Normal but significant condition
6 — informational: Informational message only
7 — debugging: Appears during debugging only


import logging
logging.basicConfig(level=logging.DEBUG)
logging.info('Info. Blah blah')
logging.warning('Warning. Meh mien lepke')


Scalability:
- Vertical (scale up/down),
- Horizontal (scale in/out)
- Hybrid

Improving resilience:
- Circuit breaker
- Fallback (e.g. to default value)
- Retry loops
- Timeouts

Rate limiting: HTTP code 429: Too Many Requests


SOA
---
SOA  	Service-Oriented Architecture
SOAP 	Simple Object Access Protocol
WSDL 	Web-Service Description Language
BPEL 	Business Process Execution Language

ESB  	Enterprise Service Bus
EDA  	Event-driven Architecture
MQ 	 	Message Queue

SOA service types:
- business
- enterprise
- application
- infrastructure

Microservice service types:
- Functional
- Infrastructure

Microservice is more granular.



ECB Design Pattern
------------------
ECB  Entity Control Boundary
MVC  Model View Controller

Entity   	-  Model
Controll 	-  Controller
Boundary  	-  View



UML
---
Unified Modeling Language


Example using PlantUML text language:

	@startuml

	actor writer
	participant CMS
	actor reviewer
	participant Web

	-> writer : Get topic

	activate writer
	writer -> writer : Research topic
	writer -> writer : Create draft

	writer -> CMS : Submit draft

	activate CMS
	CMS -> reviewer : Send draft

	activate reviewer
	reviewer -> reviewer : Review draft
	reviewer -> CMS : Provide feedback
	deactivate reviewer

	CMS -> writer : Send feedback
	deactivate CMS

	alt Draft not OK
	   writer -> writer : Implement feedback
	   writer -> CMS : Submit draft

	   activate CMS
	   CMS -> reviewer : Send draft

	   activate reviewer
	   reviewer -> reviewer : Review draft
	else Draft OK
	   reviewer -> CMS : Approve draft
	   deactivate reviewer
	   CMS -> writer : Send approval
	   deactivate CMS
	end

	writer -\ CMS : Publish document
	deactivate writer

	activate CMS
	      CMS -> Web : Publish document
	      activate Web
	        CMS <- Web : Document published
	      deactivate Web
	deactivate CMS

	Web -\ : Notify Subscribers

	@enduml


Webex / Meraki
--------------
import requests

# Webex Teams REST API:
# Set Authorization HTTP header to "Bearer ACCESS_TOKEN" where ACCESS_TOKEN is your Webex Access Token
#
requests.get('https://api.ciscospark.com/v1/messages', headers={'Authorization': 'Bearer ACCESS_TOKEN')


# Meraki REST API:
# Set X-Cisco-Meraki-API-Key HTTP header to the Meraki API Key string that has been generated
# via https://dashboard.meraki.com/
#
requests.get('https://api.ciscospark.com/v1/messages', headers={'X-Cisco-Meraki-API-Key': 'MERAKI-API-KEY')


+++ Verder gaan bij 3.6 +++
Use Cisco Webex Teams API to Enable ChatOps



Security
--------
PKI		Public Key Infrastructure
GDPR	General Data Protection Regulation
PII 	Personal Identifiable Information data protection
OCSP	Online Certificate Status Protoco
SCEP 	Simple Certificate Enrollment Protocol

Pseudonymization:
- anonymization
- deidentification

FDE 	Full Disk Encryption
HSM 	Hardware Security Module


RFC 8446	TLS version 1.3

TLS_RSA_WITH_AES_128_CBC_SHA:  +++ klopt dit wel ?? +++ sha for auth too?; RSA for key exchange? Of mixed?
- RSA  authentication
- AES  confidentiality
- SHA  integrity; digital signatures.


Create a Public Key Certificate:
- Generate Private Key: 					openssl genrsa -aes192 -out PRIVATEKEY.key 4096
- Generate Certificate Signing Request: 	openssl req -new -key PRIVATEKEY.key -out CSR.csr
- Check the CSR:							cat CSR.csr; Digicert CSR Check: https://ssltools.digicert.com/checker/views/csrCheck.jsp
- Enroll CSR with CA
- Install certificate


Service meshes using TLS:
- Linkerd
- Istio



OWASP	Open Web Application Security Project
XXE		XML External Entities
XSS		Cross-Site Scripting
CSRF	Cross-Site Request Forgery (sometimes pronounced sea-surf)
XSRF	Cross-Site Request Forgery
SSRF	Server-Side Request Forgery


Risk = Likelyhood x Impact

Likelyhood is an average of:
- Exploitability
- Weakness Prevalence
- Weakness Detectability

OWASP top 10 (2017)
1.  Injection
2.  Broken Authentication
3.  Sensitive Data Exposure			<== most prevalent and impactful
4.  XML External Entities (XXE)
5.  Broken Access Control
6.  Security Misconfiguration
7.  Cross-Site Scripting (XSS)
8.  Insecure Deserialization
9.  Vulnerable Components
10. Insufficient Logging & Monitoring


Cerberus data validator:	https://docs.python-cerberus.org/en/stable/

	>>> schema = {'name': {'type': 'string'}}
	>>> v = Validator(schema)

	>>> document = {'name': 'john doe'}
	>>> v.validate(document)
	True



XSS enables attackers to inject client-side scripts into web pages viewed by other users.

CSRF/XSRF also known as one-click attack or session riding.
Malicious exploit of a website where unauthorized commands are transmitted from a user that the web application trusts without the user's interaction or even knowledge. Unlike cross-site scripting (XSS), which exploits the trust a user has for a particular site, CSRF exploits the trust that a site has in a user's browser.

Python:
- HTML.Escape to escape HTML
- Sanitize library for HTML input sanitization


Python frameworks supporting CSRF tokens:
- Django
- Flask-WTF
- Flask-SeaSurf
- Pyramid
- Sanic-WTF

WTF = WTForms


OAuth
-----
RFC6749: OAuth 2.0 Authorization Framework

OAuth roles:
- Resource owner
- Client (the application)
- Authorisation server
- Resource server

OAuth interaction models:
- Resource Owner Password Credentials flow
- Client Credentials flow
- Authorization Code Grant flow
- Implicit flow

OAuth 2.0 grant types:
- Authorization Code grant
- Client Credentials grant
- Device Code grant
- Refresh Token grant
- Password grant (Legacy)

Two-Legged authorization flow:
- Two flows
- Client application, authorization server and a resource server
- Two-Legged authorization flow is mostly used for APIs

Three-Legged authorization flow:
- Tree flows
- Resource owner, client application, authorization server and a resource server
- Three-Legged authorization flow is mostly used for end-user authentication.

Three-Legged authorization steps.
- Retrieve authorization code.
- Exchange authorization code for an access token.
- Use the access token.


Grant type used in the two-legged authorization flow: client_credentials

	POST /token HTTP/1.1
	Host: authorization-server.com
	Content-Type: application/x-www-form-urlencoded

	grant_type=client_credentials
	client_id=xxxxxxxxxx
	client_secret=xxxxxxxxxx


Authentication (?) protocols authorization server:
- OAuth
- OpenID

Access token:  lifetime 60 minutes
Refresh token: lifetime 60 days


Revoke token:

	POST /revoke HTTP/1.1
	Host: authorization-server.com
	Content-Type: application/x-www-form-urlencoded
	Authorization: Bearer <access_token>

	token=<access_token>


Check:
- Mitigation Cross-Site Scripting (XSS) attacks
- Mitigation CSCF attacks


OAuth sequence:
+++
+++


Python
------
Installing Python Packages:
pip install <packageName>
pip install -r requirements.txt

pip show <packageName>
pip list

pip freeze > requirements.txt
cat requirements.txt
pip install -r requirements.txt


# Create a virtual environment
# python3 -m venv <virtualenv>
python3 -m venv venv

# Activate virtual environment
source venv/bin/activate

# Deactivate virtual environment
deactivate



Creating packages with setuptools library. Example setup.py script:

	from setuptools import setup, find_packages
	setup(
	    name='my_package',
	    version='1.0.0',
	    packages=find_packages()
	)


# Make sure you have the latest versions of setuptools and wheel installed:
#
python3 -m pip install --user --upgrade setuptools wheel

# Generate distribution archive(s):
# - .tar.gz file is a source archive
# - .whl file is a built distribution (a wheel)
#
python3 setup.py sdist bdist_wheel



Pipenv dependency manager:
- Pipfile (project libraries minimum requirements; populated by installs)
- Pipfile.lock (final snapshot of currently installed versions; after lock cmd)

pipenv graph


Git
---
VCS	Version Control Software
CI 	Continuous Integration
CD 	Continuous Deployment

Main git concepts:
- Remote repository
- Local repository
- Staging area
- Working directory


# Initialize a git repository (creates .git directory)
git init

# Cloning a remote repository
git clone <url> <local dir>
git clone <url> .


# Get the status (local working directory, staging area, etc.)
git status

# Check diffs with staging area
git diff
git diff --staged

# Add a file to staging area
git add <file>
git add .

# Remove a file from staging area
git reset <file>
# Remove all file from staging area
git reset

# Commit files in staging area
git commit -m "My first commit"

# Push changes
git push


# History log of commits
git log
git log --oneline


# Create a local branch called my_test_branch
git branch my_test_branch

# Jump to branch (git put files in your working directory)
git checkout my_test_branch

# Merge my_test_branch with master
git merge my_test_branch


# Stash away unfinished branch
git stash push -m "Store temporary"

# Restore unfinished branch
git stash pop


# Other git 'merge' options:
- git rebase <dev branch>
- git cherry-pick <commit-hash>


# Rollback several commits
# by reverting to specific commit.
#
git revert <hash>

# Reset
git reset --hard
git reset --mixed
git reset --soft


# View information about remote repository
git remote -v

git remote add origin https://github.com/Tisipi/Help-Files.git

+++
git pull: combines git fetch and git merge
git push -u <remote> <branch name> com
+++


# Check the content of a git object
#
git cat-file -p master
git cat-file -p <SHA1>

# Check the type of a git object
#
git cat-file -t <SHA1>


# List files in git working directory
#
git ls-files --modified

# List files in git staging area
#
git ls-files --stage


++++ 7.4 +++++




Distributed Systems
===================

Principles large scale distributed applications:
- Availability
- Performance
- Transparency
- Scalability


HAProxy frontend example:

	frontend http
	  bind *:80
	  mode http
	  acl url_img path_beg /images
	  use_backend img-backend if url_img
	  default_backend web-backend

HAProxy backend example:

	backend web-backend
	   balance roundrobin [leastconn|source]
	   mode http
	   server web1 web1.example.com:80 check
	   server web2 web2.example.com:80 check


Types of load balancers:
- Layer 4 (Transport layer)
- Layer 7 (Application layer)


HAProxy
Linux Virtual Servers (LVS) (L4)
NGINX


Reasons to use APIs to interact with web services:
- Lightweight
- Flexible
- Scalable
- Platform-agnostic


GET
POST
PUT
PATCH
DELETE


Alternatives to REST: gRPC, RPC, SOAP, CORBA


Cisco DNA Center API:
- Northbound API aka Intent API
- RESTful
- HTTPS: GET, POST, PUT, and DELETE
- JSON
- https://developer.cisco.com/docs/dna-center/api/1-3-1-x/


Generate DNA token:
POST <cluster-ip>/dna/system/api/v1/auth/token
with basic authorization header with username and password

HTTP response code 200 Json token:
	{
	    "Token": "eyJ0eXA ... O5uEMR-tc“
	}

GET <cluster-ip>/dna/intent/api/v1/network-device
with X-Auth-Token header


Example:

	import requests

	base_url = 'https://<hostname>'
	r = requests.post(f'{base_url}/dna/system/api/v1/auth/token',
	                         auth=('<USERNAME>', '<PASSWORD>'))
	r.raise_for_status()
	token = r.json()['Token']

	headers = {'X-Auth-Token': token}
	r = requests.get(f'{base_url}/dna/intent/api/v1/site-health', headers=headers)
	r.raise_for_status()
	sites = r.json()['response']


Example SDK (Cisco Intersight API):

	from intersight.intersight_api_client import IntersightApiClient
	import intersight.apis.network_element_summary_api as summary_api

	client = IntersightApiClient(
	    host='https://intersight.com/api/v1',
	    private_key='<KEYFILE>',
	    api_key_id='<ID>'
	)
	api = summary_api.NetworkElementSummaryApi(client)
	summary = api.network_element_summaries_get()



Event-Driven Architecture (EDA)
-------------------------------
Atomic or simple event.
Related events or event stream.
Behavioral or complex events.

Loosely coupled and well distributed.
Scalability and performance.

Event Emitter
Event Channel
Event Consumer

EDA characteristics:
- Asynchronous
- Real-time
- Fine-grained
- Unicast & Multicast
- Event Ontology

EDA topologies:
- Mediator topology
- Broker topology

Mediator topology components:
- Event queue
- Event mediator
- Event channel
- Event processor

Broker topology:
Message broker: collection of event channels (message queue)


Microservices
-------------
Microservices architecture characteristics:
- Independent evolution and deployment
- Independent scalability
- Availability
- Modularity preservation
- Independent technology and language stack


Logging
-------
Aggregate logging techniques:
- Log replication
- Centralized syslog repositories
- Distributed log collection


Distributed logging stages:
- Collection (by collector agents)
- Forwarding (to log aggregator)
- Storage 	 (in object storage)
- Indexing   (into different data sets; optional)
- Alerting	 (based on thresholds and patterns; optional)


ELK stack:
- Elasticsearch
- Logstash
- Kibana
Beats is used as collector agent

Distributed tracing frameworks: OpenTracing and OpenCensus (merged into OpenTelemetry)


ssh root@dev.app.local -p 12005
service config status
service config start

service app status
service app start

Graylog filter: source:front* AND INFO


+++++++
Verloren:
9.9 Application Monitoring with Cisco AppDynamics
9.10 Limitations of Distributed Systems and CAP Theorem
9.11 Overcoming Challenges in Distributed Systems
+++++++


Deploying Applications
----------------------

12-Factor App
-------------
Adam Wiggins, 2012, Heroku; https://12factor.net

The Twelve Factors:
 1. Codebase				One codebase tracked in revision control, many deploys
 2. Dependencies			Explicitly declare and isolate dependencies
 3. Config					Store configuration in the environment
 4. Backing services		Treat backing services as attached resources
 5. Build, release, run		Strictly separate build and run stages
 6. Processes				Execute the app as one or more stateless processes
 7. Port binding			Export services via port binding
 8. Concurrency				Scale out via the process model
 9. Disposability			Maximize robustness with fast startup and graceful shutdown
10. Dev/prod parity			Keep development, staging, and production as similar as possible
11. Logs					Treat logs as event streams
12. Admin processes			Run admin/management tasks as one-off processes


Version control system (VCS): Git, Subversion (SVN), Mercurial

Package managers:
- NuGet (.NET). Dependency manifest file in json.
- Maven or Gradle (Java).
- npm package manager (Node Javascript). Json dependency declaration file (npm install).
- Pip (Python). Dependency manifest text file (pip install -r requirements.txt).

Examples backing services:
- Data stores (Mysql, PostgreSQL)
- Messaging systems
- SMTP services (Postfix)
- Caching systems (Memcached, redis)
- External authentication providers (Auth0).

Example Web Servers:
- Apache, NGINX (open source)
- Tomcat and JBoss (Java)
- Microsoft Internet Information Server (IIS)  (.NET)

A 12-factor app should not rely on runtime injection of web servers. A self-contained application declares web server libraries as dependencies, e.g.:
- Tornado (Python)
- Jetty (Java)
Export services via port binding.

Beanstalkd: background processing queueing software.

Adapters: Abstraction to different backing services. e.g. databases (SQLite, PostgreSQL) in dev, staging and prod. Example adapter: ActiveRecord.
Con: Might cause problems, e.g. tiny incompatibilities between dev and prod.

Read Eval Print Loop (REPL) shell.



Hypervisors
-----------
- Type-1, native or bare-metal hypervisors. Run directly on the host's hardware.
  Examples: Xen, Oracle VM Server, Microsoft Hyper-V, VMware ESXi.
- Type-2 or hosted hypervisors. Run on OS. Runs as a process on the host.
  Examples: VMware Workstation/Player, VirtualBox, Parallels Desktop for Mac, QEMU.

The distinction between these two types is not always clear.


Docker
------
Apache 2.0 open-source license.

Docker editions:
- Engine community
- Engine enterprise
- Enterprise with full management support

Linux xommand "ps aux" lists all processes (incl. docker containers)

Docker client-server architecture:
- Client using CLI
- Server, Docker daemon

Docker also supports a REST API
Docker daemon manages containers, images, networks and volumes.

Docker registry:
- Public: Docker Hub (https://hub.docker.com),
- Self-hosted: Harbor or GitLab Container Registry

Docker uses Union File System (unionFS) to layer Docker images.
- unionFS allows files and directories of separate file systems, known as branches, to be transparently overlaid, forming a single coherent file system.
- Layers or intermediate images.
- Image can start with a blank layer called scratch (base image).
- Image can take an existing parent image as base.


Dockerfile example:

	FROM 	ubuntu:18.04
	COPY 	. /app
	RUN 	make /app
	CMD 	python /app/app.py


Dockerfile example:

	FROM 	python:3.7
	ENV 	MESSAGE HELLO-WORLD

	COPY 	. /app
	WORKDIR /app

	RUN 	pip install -r requirements.txt
	EXPOSE 	7777

	ENTRYPOINT	["python3"]			<< This is the command
	CMD 		["myApp.py"]		<< This is the argument


Dockerfile example:

	FROM 	python:3.7
	ENV 	MESSAGE HELLO-WORLD

	COPY 	. /app
	WORKDIR /app

	RUN 	pip install -r requirements.txt
	EXPOSE 	7777

	CMD 	python3 myApp.py



FROM 		creates a layer from the ubuntu:18.04 Docker image.
COPY 		adds files from your Docker client’s current directory.
RUN 		builds your application with make.
CMD 		specifies what command to run within the container.

WORKDIR		Changes working directory for any consecutive commands.
EXPOSE 		Exposed port (only for documentation; must use --publish)
ENV 		environment variables (key value)
ENTRYPOINT

If you don't use RUN either ENTRYPOINT or CMD must be defined.
Two modes: shell and exec.
Exec format: Arguments are inside square brackets.

Exec mode is preferred. It starts the specified command process as PID 1. Ensures that unix signals sent to the container are sent to your spawned process.



# Build an image from the dockerfile
#
docker build -t <image-tag>
docker build -t <image-tag> .
docker build -t <image-tag> -f <path to Dockerfile>

# Push image to registry
#
docker push <image-tag>



# Create and run a container (fetches image automatically, if needed)
#
# docker run -dit --name <name container> -p <host port>:<container port> <image:version>
#
# 	-d (--detach)		detached mode (in background)
# 	-i (--interactive)	interactive session
# 	-t (--tty)			standard input terminal
# 	-p (--publish) 		Publish a port outside the container
#	--name 				Optional name of container
#

# Run busybox:
#
docker run busybox echo hello, world
docker run busybox pwd
docker run busybox ping 8.8.8.8

# Run Apache httpd web server
#
docker run -dit -p 8080:80 httpd
docker run -dit -p 8080:80 httpd:2.4

# Run Apache httpd web server
#
docker run -dit --name MyApacheWeb -p 8080:80 httpd:2.4


# Instead of running Apache httpd web server
# jump into the bash shell (for example for troubleshooting).
#
# You now need to start the container manually from the bash shell...
# Can be used to run one-off containers with diagnostic or maintenance commands...
# Containers stops when you exit bash shell...
#
docker run -dit --name MyApacheWeb -p 8080:80 httpd:2.4 bash


# Access the bash shell after starting the container.
#
docker run -dit --name MyApacheWeb -p 8080:80 httpd:2.4 bash
docker exec -it <containerid> bash



# List running containers:
#
docker ps
docker container ls

# List all containers that have run:
#
docker ps --all
docker container ls -a

# Check logs of container
#
docker log <container id>

# Remove stopped containers, docker cache, etc.:
#
docker system prune



# Fetch image explicitly from registry
#
# docker pull [OPTIONS] NAME[:TAG|@DIGEST]
#
docker pull debian
docker pull debian:jessie


# Check which images are present locally
#
docker images
docker image ls


#  Create a container without starting it
#
docker create hello-world

# Create and start a container.
#
docker create hello-world
docker start -a <container reference>

# Restart a stopped container.
# First three characters of id suffice.
#
docker start <container id>

# Restart a stopped container; attach to STDOUT/STDERR.
#
docker start -a <container id>


# Stop a running container
#
docker stop <container id>
docker kill <container id>


# Help
#
docker --help.


# New docker syntax available:
# docker container run
# docker image build


Docker networking
-----------------
Network drivers:
- Bridge
- Host
- Overlay
- Macvlan
- None

Built-in DNS resolution:
- Default bridge network: Container can only access other container by IP addres.
- Custom bridge network: Automatic DNS resolution between containers.

Containers connected to default bridge network, can not speak to external hosts.
To enable forwarding:
1. Allow IP forwarding on host:
   	sysctl net.ipv4.conf.all.forwarding=1
2. Update iptables FORWARD policy to ACCEPT traffic:
   	iptables -P FORWARD ACCEPT



# List Docker networks
#
docker network ls


# Create a container network
#
# docker network create [OPTIONS] NETWORK
#
docker network create my-bridge-network
docker network create -d bridge my-bridge-network

docker network create --driver=bridge --subnet=192.168.0.0/16 br0

docker network create \
  --driver=bridge \
  --subnet=172.28.0.0/16 \
  --ip-range=172.28.5.0/24 \
  --gateway=172.28.5.254 \
  br0


docker network create -d overlay my-multihost-network

docker network create -d overlay \
  --subnet=192.168.10.0/25 \
  --subnet=192.168.20.0/25 \
  --gateway=192.168.10.100 \
  --gateway=192.168.20.100 \
  --aux-address="my-router=192.168.10.5" --aux-address="my-switch=192.168.10.6" \
  --aux-address="my-printer=192.168.20.5" --aux-address="my-nas=192.168.20.6" \
  my-multihost-network


# Attach container to a network upon creation
#
docker run -it -p 5000:5000 --network multi-host-network container1


# Connect a container to a network
#
# docker network connect [OPTIONS] NETWORK CONTAINER
# docker network connect [OPTIONS] <net-id> <container-id>
#
docker network connect multi-host-network container1
docker network connect --ip 10.10.36.122 multi-host-network container2


# Disconnect a container from a network
#
# docker network disconnect [OPTIONS] NETWORK CONTAINER
# docker network disconnect [OPTIONS] <net-id> <container-id>
#
docker network disconnect multi-host-network container1


Persistent Data
---------------
Restarting a container: Filesystem data is not lost
Remove a container:		Filesystem data is lost

Persist data with:
- Volume: 		Location outside of container union FS (/var/lib/docker/volumes).
				Not accessible to non-Docker processes.
- Bind mount:	Any location on host. Accessible to non-Docker processes.
- tmpfs mount:	System memory on host.

Volumes are the best way.
A volume can be mounted into multiple containers simultaneously.


# List the volumes
#
docker volume ls

# Inspect a volume
#
docker volume inspect <volume name>


# Create a volume
#
# docker volume create [OPTIONS] [VOLUME]
#
docker volume create <name volume>


# Create a volume when starting the container
#
# volume:						my-volume
# maps host local path 			/var/lib/docker/volumes/my-volume/
# into the container at 	 	/var/lib/app-data
# container:					my-app
#
docker run -d -v my-volume:/var/lib/app-data my-app


# Bind mount can only be specified with the docker run command.
# The path always starts with the forward slash (/)
#
docker run -d -v /home/cisco/app-folder:/var/lib/app-data my-app



Docker Exercise
---------------
app/main.py:

	from flask import Flask

	app = Flask(__name__)

	@app.route('/')
	def home():
	    out = (
	        f'Welcome My Friend.<br>'
	    )
	    return out

	if __name__ == '__main__':
	    app.run(debug=True, host='0.0.0.0')


Access the application:
	http://localhost:5000


app/requirements.txt:

 entry Flask==1.1.1


app/Dockerfile:

	FROM python:3.7

	COPY . /app
	WORKDIR /app

	RUN pip install -r requirements.txt
	EXPOSE 5000

	CMD ["python3", "main.py"]

Build the container:
	docker build -t app .

Start the container:
	docker run -it -p 5000:5000 app


lb/nginx.conf:

	events {}
	http {

	  upstream myapp {
	    server 172.20.0.100:5000;
	    server 172.20.0.101:5000;
	  }

	  server {
	    listen 8080;
	    server_name localhost;

	    location / {
	      proxy_pass http://myapp;
	      proxy_set_header Host $host;
	    }
	  }

	}


lb/Dockerfile:

	FROM nginx

	COPY nginx.conf /etc/nginx/nginx.conf

	EXPOSE 8080

	CMD ["nginx", "-g", "daemon off;"]


Build the container:
	docker build -t lb .


app/main.py:

	from flask import Flask
	import socket

	ip = socket.gethostbyname(socket.gethostname())

	app = Flask(__name__)

	@app.route('/')
	def home():
	    out = (
	        f'Welcome to Cisco DevNet.<br>'
	        f'IP address of the server is {ip}.<br><br>'
	    )
	    return out

	if __name__ == '__main__':
	    app.run(debug=True, host='0.0.0.0')


Create and inspect docker network appnet:
	docker network create --subnet=172.20.0.0/24 --gateway=172.20.0.1 appnet
	docker network inspect appnet

Run the app container on the appnet network with .100 IP address:
	docker run --net appnet --ip 172.20.0.100 -it -d -p 5000:5000 app

Start the lb container on the appnet network with .10 IP address:
	docker run --net appnet --ip 172.20.0.10 -it -d -p 8080:8080 lb

Access the application via the LB:
	http://localhost:8080


Databases
=========
ERM 	Entity relationship modeling
ERD 	entity relationship diagram
LDM		logical data model
PDM		physical data model

Entity, Attributes, Relationship
weak entities
cardinality, modality

Crow’s Foot Notation
->O 	zero or more
->|		1 or more
-||		1 and only 1 (exactly one)
-|0		zero or 1


Non-relational DBs:
- Scalability and flexibility
- 3 Vs: volume, velocity, and variety.
- Denormalization, Aggregation, Data distribution (sharding and replication)

Atomicity, Consistency, Isolation, Durability (ACID Compliance; e.g. Relational DB)
Consistency, Availability, Partition (CAP) theorem

DB Types
- Relational
- Key-value database
- Document-based database
- Column-based database
- Time-series database
- Graph-based database


Key-value DB:
- Simplicity
- Speed
- Scalability


Document-based DB (document store)
- Semi-structured data
- Collections of documents
- Quick iterations and frequent code pushes (agile sprints)
- Fast inserts
- Easy indexing
- Loose schema
- Evolving very fast

Examples: MongoDB, Amazon DynamoDB ?


Graph-based DB:
- nodes and edges
- example: Neo4j

Useful for:
- Social graph
- Intent graph
- Consumption graph
- Interest graph
- Mobile graph

Not suitable for:
- Processing high volumes of transactions
- Data warehouses
- Large volume analytical queries
- Mass analytics across all relations



OLTP	Online transaction processing
OLTA	Online transaction analysis


Columnar-based DB:
- Range-based queries
- Aggregate operations (AVG, SUM, MIN, MAX)

OLTP	row-based database
OLTA	colums-based database

Data warehouses
Business intelligence (BI)
Big data
Library card catalog
Ad-hoc query systems

Examples: Cassandra, HBase



SQL Exercise
------------
...

SELECT COUNT(*) FROM rides;


EXPLAIN ANALYSE SELECT date_trunc('hour', pickup_datetime) as timeframe, COUNT(*) FROM rides GROUP BY timeframe ORDER BY timeframe;

	EXPLAIN ANALYSE
	SELECT date_trunc('hour', pickup_datetime) as timeframe,

	COUNT(*) FROM rides
	GROUP BY timeframe
	ORDER BY timeframe;


Same query but now with TimescaleDB’s time bucket aggregation tool (10% faster):

EXPLAIN ANALYSE SELECT time_bucket('5 minutes', pickup_datetime) AS timeframe, COUNT(*) FROM rides GROUP BY timeframe ORDER BY timeframe;

	EXPLAIN ANALYSE
	SELECT time_bucket('5 minutes', pickup_datetime) AS timeframe,

	COUNT(*) FROM rides
	GROUP BY timeframe
	ORDER BY timeframe;



MongoDB Exercise
----------------
# Select the DEVNET database
use DEVNET

# List the collections
db.getCollectionNames()

# Display a document from the collection
db.zips.findOne()

# List the number of documents
db.zips.find().count()

# Now count the number of documents, having non-null values
db.zips.find({$and:[{city:{$exists:true}},{loc:{$exists:true}},{pop:{$exists:true}},{state:{$exists:true}}]}).count().

	db.zips.find(
		{$and:
			[
				{city:{$exists:true}},
				{loc:{$exists:true}},
				{pop:{$exists:true}},
				{state:{$exists:true}}
			]
		}
	).count().


# Get the total population of each state.
#
db.zips.aggregate([{$group:{"_id":"$state", "total_pop":{"$sum":"$pop"}}}])

	db.zips.aggregate(
		[
			{
				$group:{"_id":"$state", "total_pop":{"$sum":"$pop"}}
			}
		]
	)

# Iterate through the rest of the output.
it


# Display population of the western part of the USA (left of the 100th meridian)
# Sort results alphabetically
#
db.zips.aggregate([{"$match":{"loc.0":{"$lt": -100}}}, {"$group":{"_id":"$state", "total_pop":{"$sum":"$pop"}}}, {"$sort": {"_id": 1}}])

	db.zips.aggregate(
		[
			{"$match":{"loc.0":{"$lt": -100}}},
			{"$group":{"_id":"$state", "total_pop":{"$sum":"$pop"}}},
			{"$sort": {"_id": 1}}
		]
	)


db.zips.mapReduce(function(){if (this.loc[0] < -100{emit(this.state, this.pop);})},function(state, pop){return Array.sum(pop);}, {out: "Total_Population_West"})

	db.zips.mapReduce(
		function() {
			if (
				this.loc[0] < -100 {
					emit(this.state, this.pop);
				}
			)
		},
		function(state, pop){
			return Array.sum(pop);
		},
		{out: "Total_Population_West"}
	).


Neo4j Graph Database
--------------------
MATCH (n) RETURN n

the actors with the movies they played in and display the actors who played in the most Bond movies with the

MATCH (p:People)-[:AS_BOND_IN]->(m:Film)
RETURN p.Name AS ActorName, count(p.Name) AS BondMovies ORDER BY BondMovies DESC


 Try querying for the most commonly used car brand that Sean Connery drove in his movies.
 As you can see, he drove a Ford card 16 times in all his movies.

MATCH (p:People)-[:AS_BOND_IN]->(m:Film)-[:HAS_VEHICLE]->(v:Vehicle)
WHERE p.Name='Sean Connery'
RETURN p.Name as Actor, v.Brand as Car, COUNT(p.Name) as Count
ORDER BY COUNT(p.Name) DESC LIMIT 1)





Setting up your Linux/Ubuntu workstation
----------------------------------------
# Basic Linux tools and utilities
# wget is already installed
#
sudo apt-get install curl


# Postman
# Install via snap. If not installed yet: sudo apt install snapd
sudo snap install postman


# Developer tools and utilities:
# - Equivalent to openssl-dev on other distributions
# - For example the gcc C compiler
#
sudo apt-get install libssl-dev
sudo apt-get install build-essential


# Git
#
sudo apt-get install git
git --version


# Python
#
sudo apt-get install python3
sudo apt-get install python3-pip


# Python3-venv
sudo apt-get install python3-venv

# Create a virtual environment
# python3 -m venv <virtualenv>
python3 -m venv venv

# Activate virtual environment
source venv/bin/activate
python -V

# Deactivate virtual environment
deactivate


# Install Nodejs
sudo apt-get install nodejs
# Install NPM (Node Package Manager)
sudo apt-get install npm
nodejs -v
npm -v


# ngrok
cd /opt
sudo wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip
sudo unzip ngrok-stable-linux-amd64.zip
sudo mv ngrok /usr/local/bin

# Start an ngrok tunnel.
ngrok http 6767


# Google Chrome
installed via Software installer...


# install OpenConnect (open source VPN client)
sudo apt-get install openconnect
openconnect -b <ipAddress>

sudo ps -ax | grep openconnect
sudo kill <openconnect PID>



# Docker
#
# Install HTTPS plugins
#
sudo apt install apt-transport-https ca-certificates curl software-properties-common

# Ddd the GPG key for the official Docker repository to the system
#
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

# Add the Docker repository to APT sources to always check for the latest version.
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
	or
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable edge test"

# Update the package database with the Docker packages from the newly added repo
# Install Docker Community Edition.
#
sudo apt update
sudo apt install docker-ce

# Set up group permissions so you don’t need sudo for every docker command.
# Add your user to the docker group.
#
sudo usermod -aG docker <user>

# Verify Docker
sudo systemctl status docker
docker run busybox
docker ps -a


Git
---
git clone https://github.com/CiscoDevNet/dnav3-code

git status
git diff


# Create your own branch locally (called mycode)
git checkout -b mycode

# Refresh your local repository from the one on GitHub.
# Update your local repository with the remote updates.
git fetch


# Rollback all changes in a specific file.
# Checkout the last version of the file.
git checkout <changed file>

# Revert all files.
# Reset your working directory to the last commit.
git reset --hard

# Delete a branch.
git branch --delete --force <branch name>


# Set global settings
git config --global user.name "Tisipi"
git config --global user.email "Tisipi@tisipi.com"

# List global configured settings
git config --list


# Add a specific file to staging area
git add <file>

# Add files from current directory to staging area
git add .


# Commit files in staging area
git commit -m "Initial commit"



API
---
HTTP Verb	Typical Action (CRUD)
POST		Create
GET			Read
PUT			Update
PATCH		Update
DELETE		Delete

Status Code	Status Message	Meaning
200	OK						All looks good
201	Created					New resource created
400	Bad Request				Request was invalid
401	Unauthorized			Authentication missing or incorrect
403	Forbidden				Request was understood but not allowed
404	Not Found				Resource not found
500	Internal Server Error	Something wrong with the server
503	Service Unavailable		Server is unable to complete request


curl -X		followed by a request verb such as GET, PUT, POST, PATCH, or DELETE.
curl -H 	followed by a header such as a token to send with the requests.


curl https://deckofcardsapi.com/api/deck/new/ | python -m json.tool
curl https://deckofcardsapi.com/api/deck/new/ | python3 -m json.tool

curl https://deckofcardsapi.com/api/deck/i5esttp06r1z/shuffle/
curl https://deckofcardsapi.com/api/deck/i5esttp06r1z/draw/?count=3 | python -m json.tool
curl https://deckofcardsapi.com/api/deck/9ujz1q9z2hnk/draw/?count=3 | python -m json.tool

https://deckofcardsapi.com/api/deck/{{deck_id}}/draw/?count=3


curl https://api.ciscospark.com/v1/people/me

curl https://api.ciscospark.com/v1/messages -X POST -H "Authorization:Bearer NDc0OWI3NWMtNjc3ZS00ZDM4LWE3MzktNWYyYmMxYWY2YjIxMWQ0ZjI5ZjAtM2Yz_PF84_e1a492ed-2b3b-4ab5-b37e-e7a31a6a4d57" --data "toPersonEmail=myEmail@email.nl" --data "text=Hi%20from%20DevNet"

curl https://api.ciscospark.com/v1/teams -X GET -H "Authorization:Bearer M2RiZWQyMDItMDdhYi00NTA1LTgwOTQtMjUzMTc4YThhZDI4YjU4NmJmNmMtZWQ3_PF84_e1a492ed-2b3b-4ab5-b37e-e7a31a6a4d57"

curl -X GET https://api.ciscospark.com/v1/teams -H "Authorization:Bearer M2RiZWQyMDItMDdhYi00NTA1LTgwOTQtMjUzMTc4YThhZDI4YjU4NmJmNmMtZWQ3_PF84_e1a492ed-2b3b-4ab5-b37e-e7a31a6a4d57"



DNA - Digital Network Architecture
----------------------------------
Cisco SDN controller for the enterprise

Cisco DNA Center FAQ:
	https://www.cisco.com/c/en/us/products/collateral/cloud-systems-management/dna-center/nb-06-dna-center-faq-cte-en.html
	https://developer.cisco.com/dnacenter/
	https://developer.cisco.com/docs/dna-center/#!cisco-dna-center-platform-overview

Cisco DNA Center workflow:
- Design
- Policy (Business and application intent)
- Provision
- Assure (via Network telemetry and sensor capabilities)

SDA??


DNA lab
-------
git clone https://github.com/CiscoDevNet/dnav3-code
cd dnav3-code
python3 -m venv venv
source venv/bin/activate
cd intro-dnac/
pip install -r requirements.txt


YANG
----
# Generate tree view of Yang model.
pyang -f tree ietf-interfaces.yang



Guest Shell (on IOS-XE)
-----------------------

! Enable IOx
!
conf t
iox
exit

! Check that CAF, IOxman and Libvirtd services are running:
show iox-service



! Enable the communication between IOS XE and the Guest Shell container
! Network settings of IOS XE host
conf t
interface VirtualPortGroup0
  ip address 192.168.1.1 255.255.255.0

! Network settings of Guest Shell container  (>= IOS XE 16.7.1):
! - IP address
! - Default gateway
! - DNS server.
!
app-hosting appid guestshell
 vnic gateway1 virtualportgroup 0 guest-interface 0 guest-ipaddress 192.168.1.2 netmask 255.255.255.0 gateway 192.168.1.1 name-server 8.8.8.8


! NAT towards outside world (via outside interface Gig/1)
!
interface VirtualPortGroup0
 ip nat inside
!
interface GigabitEthernet1
 ip nat outside
!
ip access-list extended NAT-ACL
 permit ip 192.168.1.0 0.0.0.255 any
!
ip nat inside source list NAT-ACL interface GigabitEthernet1 overload


! Enable Guest Shell
!
guestshell enable
show app-hosting detail
end

! Access guestshell
guestshell
[guestshell@guestshell ~]$ whoami
[guestshell@guestshell ~]$ pwd
[guestshell@guestshell ~]$ ls /flash/

[guestshell@guestshell ~]$ sudo yum update -y
[guestshell@guestshell ~]$ sudo yum install -y git nano
[guestshell@guestshell ~]$ git --version
[guestshell@guestshell ~]$ nano --version
[guestshell@guestshell ~]$ git clone https://github.com/CiscoDevNet/dnav3-code.git


! Execute IOS XE CLI commands from within the guestshell
!
[guestshell@guestshell ~]$ dohost "show memory statistics"

! Run Guest Shell linux applications directly from IOS XE prompt
!
guestshell run groups
guestshell run cat /etc/centos-release



Cisco Live Presentations
------------------------
https://developer.cisco.com/learning/lab/why-mdp/step/7
	-	Device APIs: The Force Awakens - BRKSDN-1119
	-	Model Driven Approach to SDN with NETCONF - BRKSDN-1903
	-	YANG Data Modeling and NETFCONF: Cisco and Industry Developments - BRKNMS- 2032
	-	Network programming using Yang service models with Cisco Network Services Orchestrator - DEVNET-1177
	-	Introduction to Data Models and Cisco's NextGen Device Level APIs - DEVNET-1082
	-	Introduction to RESTCONF - DEVNET-1081
