Print LSB (Linux Standard Base) and Distribution information.
a
lsb_release -a


python --version
python -V
python2 --version
python3 --version


shebang line examples
#!/usr/bin/env python3
#!/usr/bin/python


Ubuntu:
ls /usr/lib/python3.8/dist-packages
Manjaro:
ls /usr/lib/python3.8


__init__.py



Python 3 Module of the Week
---------------------------
https://pymotw.com/3/



Basic I/O
---------
print("Hello")
print("Hello {}".format(name))

name = input("Please type your name: ")


Remark
- In Python 2 raw_input should be used to input a string
- input(x) is eval(raw_input(x)).


# Linux env variables
env
env | grep PATH
echo $PATH
export TEST_VAR="Yes Yes"

os.environ["PATH"]
os.environ.get("PATH")
os.environ.get("PATH", "")

my_env = os.environ.copy()
my_env['PATH'] = os.pathsep.join(["/opt/niceapp", my_env['PATH']])


sys.exit(0)		default exit code python script
sys.exit(1)		exit code error


sys
---
import sys

sys.stdin

sys.argv
sys.argv[0], sys.argv[1], etc.


./myCommands.py simple_commands.txt

	import sys
	import subprocess

	cmdfile = sys.argv[1]
	with open(cmdfile) as file:
	    for line in file:
	        cmd = line.strip()
	        subprocess.run([cmd])



subprocess
----------
https://docs.python.org/3/library/subprocess.html

subprocess.run(["ls"])
subprocess.run(["ps"])
subprocess.run(["date"])
subprocess.run(["sleep", "5"])
subprocess.run(["ping", "8.8.8.8"])
subprocess.run(["echo", old_file_name, new_file_name])
subprocess.run(["mv", old_file_name, new_file_name])


result = subprocess.run(["ls"])
result.returncode

result = subprocess.run(["ls"], capture_output=True)
result.stdout
result.stdout.decode().split('\n')
result.stderr


Misc
----
split()
strip()
word.lower()
word.isalpha()
replace()

punctuations = '''!()-[]{};:'"\,<>./?@#$%^&*_~'''
new_file_contents = ''.join(char for char in file_contents if char not in punctuations)


department_list.count("IT")



read /write files
-----------------
file = open('test.txt')
file.close()

with open('test.txt') as file:
    for line in file:
        print(line.strip())

line = file.readline()
next_line = file.readline()
rest_of_file = file.read()

lines = file.readlines()


modes:
'r'	open for reading (default)
'w'	open for writing, truncating the file first !!!
'x'	open for exclusive creation, failing if the file already exists
'a'	open for writing, appending to the end of the file if it exists
'b'	binary mode
't'	text mode (default)
'+'	open for updating (reading and writing)

--

Note: Byte Order Mark or BOM is used in UTF-16 to discriminate between Little-endian and Big-endian.
If your file is in UTF-8 you don't need BOM markers. To remove them use UTF-8-sig:

	with open(file_path, encoding='utf-8-sig') as csv_file:

https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/


+++
To be checked:
https://realpython.com/python-concurrency/
https://hackernoon.com/threaded-asynchronous-magic-and-how-to-wield-it-bba9ed602c32
https://stackoverflow.com/questions/33047452/definitive-list-of-common-reasons-for-segmentation-faults
https://sites.google.com/a/case.edu/hpcc/home/important-notes-for-new-users/debugging-segmentation-faults

Readable Python code on GitHub:
https://github.com/fogleman/Minecraft
https://github.com/cherrypy/cherrypy
https://github.com/pallets/flask
https://github.com/tornadoweb/tornado
https://github.com/gleitz/howdoi
https://github.com/bottlepy/bottle/blob/master/bottle.py
https://github.com/sqlalchemy/sqlalchemy

https://blog.rescuetime.com/how-to-prioritize/

https://landing.google.com/sre/sre-book/chapters/effective-troubleshooting/

+++


os
--
https://docs.python.org/3/library/os.html
https://docs.python.org/3/library/os.path.html

os.getcwd()
os.mkdir('temp_dir')
os.chdir('temp_dir')
os.rmdir('temp_dir')
os.listdir('/')
os.listdir(path='.')

os.scandir(path='.')
	Returns an iterator

	Using scandir() instead of listdir() can significantly increase the performance of code that also needs file type or file attribute information


	with os.scandir(path) as it:
	    for entry in it:
	        if not entry.name.startswith('.') and entry.is_file():
	            print(entry.name)


os.remove('my.txt')
os.rename('draft.txt', 'final.txt')
os.path.exists('draft.txt')

os.path.abspath('test_math.py')
os.path.isfile(file)
os.path.isdir(file)
os.path.join(dir, name)
os.path.dirname(path)
os.path.expanduser('~')

os.stat('somefile.txt')


# File size in bytes
os.path.getsize('draft.txt')

# Last modified time (unix time)
os.path.getmtime('draft.txt')

# Return the time of last access of path
os.path.getatime(path)


os.environ
os.environ['HOME']
os.environ['PATH']

os.getenv('HOME')
os.getenv('PATH')
os.putenv(key, value)


os.getpid()
os.getppid()
os.uname()

os.sep
os.linesep
os.pathsep


csv
---
https://docs.python.org/3/library/csv.html
https://realpython.com/python-csv/

Note: Files below should be opened with newline=''
		with open('person.csv', newline='') as csvfile:


with open('person.csv', 'r') as f:
    reader = csv.reader(f)
    for row in reader:
        name, gender, age = row

persons = [['Jan', 'Man', 32], ['Piet', 'Man' ,45], ['Joke' ,'Vrouw', 34]]
with open('my_persons.csv', 'w') as f:
    writer = csv.writer(f)
    writer.writerows(persons)


with open('personHeader.csv', 'r') as f:
    reader = csv.DictReader(f)
    for row in reader:
        print(row['Name'], row['Age'])


persons = [{'Name': 'Jan', 'Gender': 'Man', 'Age': 27},
           {'Name': 'Piet', 'Gender': 'Man' ,'Age': 45},
           {'Name': 'Joke' ,'Gender': 'Vrouw', 'Age':34}]
with open('my_persons_header.csv', 'w') as f:
    keys = ['Name', 'Gender', 'Age']
    writer = csv.DictWriter(f, fieldnames=keys)
    writer.writeheader()
    writer.writerows(persons)


csv.register_dialect('myDialect', skipinitialspace=True, strict=True)
csv.DictReader(f, dialect = 'myDialect')



math
----
math.pi


datetime
--------
unixtime = os.path.getmtime('test_math.py')
datetime.datetime.fromtimestamp(unixtime)
#datetime.datetime(2020, 10, 9, 17, 30, 52, 145723)


shutil
------
du = shutil.disk_usage("/")
du.free / du.total
du.used / du.total


psutil
------
psutil.cpu_percent()
psutil.cpu_percent(0.1)

psutil.disk_io_counters()
psutil.net_io_counters()


requests
--------
# sudo apt install python3-requests
request = requests.get("http://www.google.com")
request.status_code == 200


socket
------
localhost = socket.gethostbyname('localhost') # Returns '127.0.0.1'


re
--
https://www.regex101.com
https://regexcrossword.com/
https://docs.python.org/3/howto/regex.html
https://docs.python.org/3/library/re.html

Metacharacters: . ^ $ * + ? { } [ ] \ | ( )
Metacharacters must be escaped.

.		Any char except a newline character (in alternate mode (re.DOTALL) it matches even a newline)
?		Optional char (0 or 1 char)
*		0 or more instances
+		1 or more instances
^		Matches at the beginning of string/line (re.MULTILINE flag)
$		Matches at the end of a string/line
[]		Character class (a set of characters). For example:
			[a-z]
			[A-Z]
			[0-9]
			[a-zA-Z]
			[^a-zA-Z]
			[a-zA-Z0-9]
			[\s,.] 		match any whitespace character or ',' or '.'.

|		Alternation, “or” operator, e.g. [man|woman]
{n}		Repetition, n times
{n,m}	Repetition, n to m times (incl.)
{n,}	Repetition, n or more times
{,m}	Repetition, zero up to m times.


\d		Matches any decimal digit; this is equivalent to the class [0-9].
\D		Matches any non-digit character; this is equivalent to the class [^0-9].
\s		Matches any whitespace character; this is equivalent to the class [ \t\n\r\f\v].
\S		Matches any non-whitespace character; this is equivalent to the class [^ \t\n\r\f\v].
\w		Matches any alphanumeric character; this is equivalent to the class [a-zA-Z0-9_].
\W		Matches any non-alphanumeric character; this is equivalent to the class [^a-zA-Z0-9_].

\b		Word boundary. Matches only at the beginning or end of a word.


match()		Determine if the RE matches at the beginning of the string.
search()	Scan through a string, looking for any location where this RE matches.
findall()	Find all substrings where the RE matches, and returns them as a list.
finditer()	Find all substrings where the RE matches, and returns them as an iterator.

split()		Split the string into a list, splitting it wherever the RE matches.
sub()		Find all substrings where the RE matches, and replace them with a different string.
subn()		Does the same thing as sub(), but returns the new string and the number of replacements.


re.search(r"man", "mankind")
re.search(r"man", "Mankind", re.IGNORECASE)
re.search(r"\.nl", "tisipi.nl")

re.findall(r"man|woman", "Both man and woman")

pattern = re.compile(r"man|woman")
pattern.findall("Both man and woman")

mo = re.search(r"\[(\d+)\]", "This is a PID [1234] maestro")
mo.group()
mo.group(0)
mo.groups()


result = re.search(r" () () ", <string>)
result[1]
result[2]


re.split(r"[.!]", "Split my sentence. This one too! Is it working?")
re.split(r"([.!])", "Split my sentence. This one too! Is it working?")

p = re.compile('(blue|white|red)')
p.sub('colour', 'blue socks and red shoes')
p.sub('colour', 'blue socks and red shoes', count=1)

re.sub(r"\d+.\d+.\d+.\d+", "[HIDDEN]", "The customers IP address 11.6.6.7 must not be visible")


unittest
--------
https://docs.python.org/3/library/unittest.html#basic-example
https://docs.python.org/3/library/unittest.html#command-line-interface
https://docs.python.org/3/library/unittest.html#organizing-test-code
https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertRaises


Create module called <module>_test.py:

	import unittest

	# Test Class
	class TestWhatever(unittest.TestCase):

		# Test methods
	    def setUp(self):
	        self.widget = Widget('The widget')

	    def tearDown(self):
	        self.widget.dispose()

	    def test_whatever1(self):
	    	self.assertEqual(..., ...)

	    def test_whatever2(self):

	if __name__ == '__main__':
	    unittest.main()


assertEqual(a, b)			a == b
assertNotEqual(a, b)		a != b
assertTrue(x)				bool(x) is True
assertFalse(x)				bool(x) is False
assertIs(a, b)				a is b
assertIsNot(a, b)			a is not b
assertIsNone(x)				x is None
assertIsNotNone(x)			x is not None
assertIn(a, b)				a in b
assertNotIn(a, b)			a not in b
assertIsInstance(a, b)		isinstance(a, b)
assertNotIsInstance(a, b)	not isinstance(a, b)

assertRaises(exc, fun, *args, **kwds)			fun(*args, **kwds) raises exc
assertRaisesRegex(exc, r, fun, *args, **kwds)	fun(*args, **kwds) raises exc and the message matches regex r
assertWarns(warn, fun, *args, **kwds)			fun(*args, **kwds) raises warn
assertWarnsRegex(warn, r, fun, *args, **kwds)	fun(*args, **kwds) raises warn and the message matches regex r
assertLogs(logger, level)						The with block logs on logger with minimum level

assertAlmostEqual(a, b)		round(a-b, 7) == 0
assertNotAlmostEqual(a, b)	round(a-b, 7) != 0
assertGreater(a, b)			a > b
assertGreaterEqual(a, b)	a >= b
assertLess(a, b)			a < b
assertLessEqual(a, b)		a <= b
assertRegex(s, r)			r.search(s)
assertNotRegex(s, r)		not r.search(s)
assertCountEqual(a, b)		a and b have the same elements in the same number, regardless of their order.

assertMultiLineEqual(a, b)	strings
assertSequenceEqual(a, b)	sequences
assertListEqual(a, b)		lists
assertTupleEqual(a, b)		tuples
assertSetEqual(a, b)		sets or frozensets
assertDictEqual(a, b)		dicts


assert isinstance(item, str), "Must be a string"


Command line examples:
	python -m unittest -h
	python -m unittest test_module
	python -m unittest -v test_module
	python -m unittest test_module1 test_module2
	python -m unittest test_module.TestClass
	python -m unittest test_module.TestClass.test_method


Exceptions
----------
raise ValueError
raise NameError('This is an error')


Built-in Exception hierarchy:

	BaseException
	 +-- SystemExit
	 +-- KeyboardInterrupt
	 +-- GeneratorExit
	 +-- Exception
	      +-- StopIteration
	      +-- StopAsyncIteration
	      +-- ArithmeticError
	      |    +-- FloatingPointError
	      |    +-- OverflowError
	      |    +-- ZeroDivisionError
	      +-- AssertionError
	      +-- AttributeError
	      +-- BufferError
	      +-- EOFError
	      +-- ImportError
	      |    +-- ModuleNotFoundError
	      +-- LookupError
	      |    +-- IndexError
	      |    +-- KeyError
	      +-- MemoryError
	      +-- NameError
	      |    +-- UnboundLocalError
	      +-- OSError
	      |    +-- BlockingIOError
	      |    +-- ChildProcessError
	      |    +-- ConnectionError
	      |    |    +-- BrokenPipeError
	      |    |    +-- ConnectionAbortedError
	      |    |    +-- ConnectionRefusedError
	      |    |    +-- ConnectionResetError
	      |    +-- FileExistsError
	      |    +-- FileNotFoundError
	      |    +-- InterruptedError
	      |    +-- IsADirectoryError
	      |    +-- NotADirectoryError
	      |    +-- PermissionError
	      |    +-- ProcessLookupError
	      |    +-- TimeoutError
	      +-- ReferenceError
	      +-- RuntimeError
	      |    +-- NotImplementedError
	      |    +-- RecursionError
	      +-- SyntaxError
	      |    +-- IndentationError
	      |         +-- TabError
	      +-- SystemError
	      +-- TypeError
	      +-- ValueError
	      |    +-- UnicodeError
	      |         +-- UnicodeDecodeError
	      |         +-- UnicodeEncodeError
	      |         +-- UnicodeTranslateError
	      +-- Warning
	           +-- DeprecationWarning
	           +-- PendingDeprecationWarning
	           +-- RuntimeWarning
	           +-- SyntaxWarning
	           +-- UserWarning
	           +-- FutureWarning
	           +-- ImportWarning
	           +-- UnicodeWarning
	           +-- BytesWarning
	           +-- ResourceWarning


Python Try Except
-----------------
https://www.w3schools.com/python/python_try_except.asp:

	- The try block lets you test a block of code for errors.
	- The except block lets you handle the error.
	- You can use the else keyword to define a block of code to be executed if no errors were raised
	- The finally block lets you execute code, regardless of the result of the try- and except blocks.


https://realpython.com/python-exceptions/

	- In the try clause, all statements are executed until an exception is encountered.
	- except is used to catch and handle the exception(s) that are encountered in the try clause.
	- else lets you code sections that should run only when no exceptions are encountered in the try clause.
	- finally enables you to execute sections of code that should always run, with or without any previously encountered exceptions.
	- raise allows you to throw an exception at any time.
	- assert enables you to verify if a certain condition is met and throw an exception if it isn’t.

try:
  print(x)
except:
  print("An exception occurred")

try:
    with open('file.log') as file:
        read_data = file.read()
except FileNotFoundError as fnf_error:
    print(fnf_error)


try:
  print(x)
except NameError:
  print("Variable x is not defined")
except:
  print("Something else went wrong")


try:
  print("Hello")
except:
  print("Something went wrong")
else:
  print("Nothing went wrong")

try:
    linux_interaction()
except AssertionError as error:
    print(error)
else:
    print('Executing the else clause.')


try:
  print(x)
except:
  print("Something went wrong")
finally:
  print("The 'try except' is finished")

try:
  f = open("demofile.txt")
  f.write("Lorum Ipsum")
except:
  print("Something went wrong when writing to the file")
finally:
  f.close()



Jupyter Notebooks
-----------------
Jupyter Notebook Tutorial			https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook
How to use Jupyter Notebooks		https://www.codecademy.com/articles/how-to-use-jupyter-notebooks
Teaching and Learning with Jupyter 	https://jupyter4edu.github.io/jupyter-edu-book/


unittest.main(argv = ['ignore-this-dummy-argument'], exit = False)
	unittest.main( ) looks at sys.argv. In Jupyter the first parameter of sys.argv is what started the Jupyter kernel.
	Passing an explicit list to unittest.main( ) prevents it from looking at sys.argv.
	exit = False prevents unittest.main( ) from shutting down the kernel process.


Bash Scripting
--------------
Bash = Bourne Again shell (Steve Bourne, Bell Labs Research)

https://ryanstutorials.net/bash-scripting-tutorial/
https://linuxconfig.org/bash-scripting-tutorial-for-beginners
https://www.shellscript.sh
https://wiki.bash-hackers.org/commands/classictest

echo $SHELL


STDIN	0
STDOUT	1
STDERR	2

>	redirect STDOUT output to file
>>	redirect STDOUT output to file (but append, iso overwrite)
2>	redirect STDERR output to file

<	redirect STDIN input from file


cat pluralsight.txt | less
cat pluralsight.txt | tr ' ' '\n'
cat pluralsight.txt | tr ' ' '\n' | sort
cat pluralsight.txt | tr ' ' '\n' | sort | uniq
cat pluralsight.txt | tr ' ' '\n' | sort | uniq -c
cat pluralsight.txt | tr ' ' '\n' | sort | uniq -c | sort -n
cat pluralsight.txt | tr ' ' '\n' | sort | uniq -c | sort -nr
cat pluralsight.txt | tr ' ' '\n' | sort | uniq -c | sort -nr | head


ps ax | grep <search>

ctrl-c	SIGINT 		Terminates process cleanly
ctrl-z	SIGSTOP		Stops process (restart/continue with "fg")

kill <pid>	default is SIGTERM


ps			list processes executing in current terminal for current user
ps ax		list all processes executing for all users
ps e		shows the environment for the processes listed
fg			move stopped or background job to the foreground
bg			move stopped job to the background
jobs		lists jobs currently running or stopped
top			list top CPU processes ("q" to quit)


cd <directory>					Change directory
pwd								Print the current working directory
ls								List current directory
ls <directory>					List directory
ls -l							List long info of current directory
ls -a							List current directory (incl. hidden files)
ls -la
mkdir <directory>				Create/make directory
rmdir <directory>				Remove directory (if empty)
rm -rf <directory>				Remove directory (if not empty)
cp <old> <new>      			Copy
mv <old> <new>      			Move
touch <file>					Create an empty file (or update modification time if existing)
chmod <modifiers> <file>		Change permissions
chown <user> <file>				Changes the owner
chgrp <group> <file>			Changes the group

cat  <file>						Shows the content of the file on standard output
wc   <file>						Word Count (characters, words, lines)
file <file>						Print the file type
head <file>						Head of file (first 10 lines)
tail <file>						Tail of file (last 10 lines)
less <file>						Scroll through file ("q" to quit)
sort <file>						Sort the file alphabetically
cut OPTION... [FILE]...			Cut specific fields/character from file
cut -d' ' -f 6					Cut 6th field only (using space delimiter)
cut -d' ' -f6-					Cut starting from 6th field when using space delimiter
								e.g.: journalctl | head | cut -d' ' -f6-
basename NAME [SUFFIX]			Strip directory and suffix from filenames


echo "message"					Print message to standard output
date							Print current date
who								Print logged in users
man <command>					Manual pages
uptime							Uptime system
free							Free and used memory


# Status code last Linux command (0 is success/ok)
echo $?


collect.sh:
	#!/bin/bash
	echo "START TIME $(date)"; echo
	echo "YOU ARE $(who)"; echo
	echo "UPTIME IS"; uptime; echo

Variables:
	# Note: no spaces!
	name=Tisipi
	echo $name

	# Store results of command in variable
	files=$(ls)
	echo $files


Globs like * and ?:
	echo *.sh
	echo c*
	echo P?r*

Create an empty file:
	>test.txt

Append to file:
	echo ja zeker >> test.txt

Read a line from standard input:
	echo What is your name?
	read NAME
	echo "Hello $NAME - How are you?"

Conditional expression:
	#!/bin/bash
	if grep "127.0.0.1" /etc/hosts
	then
		echo "Loopback present"
	else
		echo "No Loopback"
	fi

	#!/bin/bash
	if grep "127.0.0.1" /etc/hosts; then
		echo "Loopback present"
	else
		echo "No Loopback"
	fi


	# https://wiki.bash-hackers.org/commands/classictest
	#
	# Bash test command
	#
	# file exists: test -e

	if test -e /etc/passwd; then
	  echo "Alright man..." >&2
	else
	  echo "Yuck! Where is it??" >&2
	  exit 1
	fi


	# Alternative test command ("[" is a test command too; "]" is an argument)

	if [ -e /etc/passwd ]; then
	  echo "Alright man..." >&2
	else
	  echo "Mmh! Where is it??" >&2
	  exit 1
	fi


	# Test if string is not empty

	if test -n "$PATH" ; then echo "Path is not empty"; fi
	if [ -n "$PATH" ]; then echo "Path is not empty"; fi


File tests:

	-e <FILE>			Tests if <FILE> exists.
	-f <FILE>			Tests if <FILE> exists and is a regular file.
	-d <FILE>			Tests if <FILE> exists and is a directory.
	-S <FILE>			Tests if <FILE> exists and is a socket file.
	-L <FILE>			Tests if <FILE> exists and is a symbolic link.
	-r <FILE>			Tests if <FILE> exists and is readable.
	-w <FILE>			Tests if <FILE> exists and is writable.
	-x <FILE>			Tests if <FILE> exists and is executable.
	-s <FILE>			Tests if <FILE> exists and has size bigger than 0 (not empty).
	<FILE1> -nt <FILE2>	Tests if <FILE1> is newer than <FILE2> (mtime).
	<FILE1> -ot <FILE2>	Tests if <FILE1> is older than <FILE2> (mtime).


String tests:

	-z <STRING>				Tests if <STRING> is empty/zero.
	-n <STRING>				Tests if <STRING> is not empty (default operation).
	<STRING1> = <STRING2>	Tests if strings are equal.
	<STRING1> != <STRING2>	Tests if strings are not equal.
	<STRING1> < <STRING2>	Tests if <STRING1> sorts before <STRING2> lexicographically (pure ASCII, not current locale!). Remember to escape! Use \<
	<STRING1> > <STRING2>	Tests if <STRING1> sorts after <STRING2> lexicographically (pure ASCII, not current locale!). Remember to escape! Use \>

Arithmetic tests:

	<INTEGER1> -eq <INTEGER2>	Tests if the integers are equal.
	<INTEGER1> -ne <INTEGER2>	Tests if the integers are NOT equal.
	<INTEGER1> -le <INTEGER2>	Tests if the first integer is less than or equal second one.
	<INTEGER1> -ge <INTEGER2>	Tests if the first integer is greater than or equal second one.
	<INTEGER1> -lt <INTEGER2>	Tests if the first integer is less than second one.
	<INTEGER1> -gt <INTEGER2>	Tests if the first integer is greater than second one.



While loop:

	i=1
	while [ $i -le 10 ]; do
	  echo "$i"
	  ((i+=1))
	done

	operation=$1
	while ! $operation && [ $i -le 10 ]; do
	  ...
	  ((i=i+1))
	done


For loop:

	for i in 1 2 3 4 5; do
	  echo "$i"
	done

	for name in John Peter Tim Steve; do
	  echo "$name"
	done

	for file in *.txt; do
	  name=$(basename "$file" .txt)
	  mv "$file" "$name.doc"
	done



operator
--------
import operator

# Sort dictionary based on its keys.
sorted(cars.items())
sorted(cars.items(), key=operator.itemgetter(0))

# Sort dictionary based on its values.
sorted(cars.items(), key=operator.itemgetter(1))

# Sort dictionary based on its values - Descending
sorted(cars.items(), key=operator.itemgetter(1), reverse=True)



Diff & Patch
------------
http://man7.org/linux/man-pages/man1/diff.1.html
http://man7.org/linux/man-pages/man1/patch.1.html


# Differences between text files
diff file1 file2

# Differences between text files using context
# The -u (unified) option tells diff to also list some of the unmodified
# text lines from before and after each of the changed sections.
diff -u file1 file2
diff -u file1 file2 > diffs.txt


# Patch proposed diffs to my file
patch my_file < diffs.txt

+++ patch -p1 +++


# Difference between directories
# Use -q to report only when files differ.
diff -q dir1 dir2

# Recursive diff
diff -rq dir1 dir2


# Display word differences between text files
wdiff [ option ... ] file1 file2

# GUI Diff Tools
meld
KDiff3
vimdiff



GIT
---
Pro Git book 			https://git-scm.com/book/en/v2
Git tutorial			https://git-scm.com/docs/gittutorial
Github Git Cheat Sheet	https://training.github.com/downloads/github-git-cheat-sheet.pdf

https://git-scm.com/doc
https://git-scm.com


sudo apt update
sudo apt install git
git --version

git config --global user.name "Tisipi"
git config --global user.email "Tisipi@tisipi.com"
git config -l

git init
git status
git add temp.py
git commit -m 'first commit'

git commit -am "Express commit: Combined add and commit"

git log
git log -2
git log --stat
git show <id>


# Git log with patches (diffs)
git log -p
git log -p -2


# Check diffs between working directory and local repository
git diff

# Check diffs between working directory and staging area
git diff --staged



# Show patches add asks if you want to add file to staging area.
git add -p


# Remove file
git rm <file>

# Rename file
git mv <file>


# Create a .gitignore file, to indicate files that shouldn't be tracked
# Helpful templates for .gitignore files at github.com/github/gitignore.
touch .gitignore


# Cloning a remote repository
git clone <url> <local dir>
git clone <url> .


# Rollback all changes in a specific file.
# Checkout the last version of the file.
# This discard changes in working directory
#
git checkout <changed file>


# Reset staged file; remove file from staging area
git reset HEAD <file>
 or
git reset <file>
 or
git restore --staged <file>

# Reset staged files interactively
git reset -p


# Change last commit message.
# This changes the commit history!
git commit --amend -m "This is the correct message"

# Forgot to include file in last commit.
# This changes the commit history!
git add <file>
git commit --amend


# Revert commit.
git revert HEAD


# Revert a specific commit.
# Does not discard any commits that came after that one.
# It creates a new revision that reverts the effects of a specified commit.
#
git revert <hash>


# Create a local branch called my_test_branch
git branch my_test_branch

# List the branches
git branch
git branch -a
git branch --all

# Jump to branch (git put files in your working directory).
# Switch branches. Checkout the branch.
#
git checkout my_test_branch


# Create and checkout a branch in one step.
git checkout -b my_test_branch


# Delete a branch.
git branch -d <branch name>
git branch --delete  <branch name>


# Delete a branch, forced (in case of unmerged changes)
#
git branch -D <branch name>
git branch -d --force <branch name>
git branch --delete --force <branch name>



# Merge my_test_branch with master
git checkout master
git merge my_test_branch

# In case of conflicts:
# - Edit the file
# - Git add the updated file
# - Git commit the updated file
nano <conflicting file>
git add <conflicting file>
git commit

# To see merge history graphically
git log --graph
git log --graph --oneline

# Abort the merge, for example in case of too many conflicts.
#
git merge --abort



# Clone a remote repository into your local workspace
git clone URL3

# Push commits from your local to a remote repository
git push

# Fetch the newest updates from a remote repository
git pull


# Caching your GitHub credentials (use the credential memory cache)
git config --global credential.helper cache

# Change the default password cache timeout (in seconds)
git config --global credential.helper 'cache --timeout=3600'


# View information about remote repository
git remote -v
git remote show origin

# Check remote branches that git is tracking locally
git branch -r


# Refresh your local repository from the one on GitHub.
# Update your local repository with the remote updates.
#
git fetch

# Check log of the remote master branch (that is tracked locally)
git log origin/master

# Merge changes of remote master branch in local master
git merge origin/master


# Git pull = Combined git fetch and git merge
# - Fetch from remote (into local repository)
# - Perform a git merge into working directory
#
git pull


# Get the contents of a remote branch without automatically merging.
git remote update


# Check log of all local and remote branches.
git log --graph --oneline --all



# Push a new local branch to the remote server
# - By default Git names the remote server 'origin' ('origin' is just an alias for the remote server).
# - Option -u sets the tracking relationship between the local branch and the new remote branch.
#
# git push -u <remote> <branch name>
#
git push -u origin my_new_branch



+++
# Push a new repository to a remote server
# - Define an alias for the remote server with: git remote add
# - Push repo to remote server with: git push -u <remote> <branch name>
#   Note that 'origin' is just an alias for the remote server; by default Git names the server 'origin'.
#
# Remark: Option -u sets the tracking relationship between the local branch and the new remote branch.
#
git remote add origin https://github.com/Tisipi/Help-Files.git
git push -u origin master
+++



# Rebase replays changes in a branch onto for example master.
# Note: This forges history
#
# https://git-scm.com/book/en/v2/Git-Branching-Rebasing
#
# - Checkout branch that you want to replay on master
# - Define in the rebase command the branch the changes shoud be replayed/rebased on.
# - Checkout master
# - Merge your branch into the master
#
git checkout <feature branch>
git rebase master
git checkout master
git merge <feature branch>

# Delete the rebased branch (remotely)
git push --delete origin <feature branch>
# Delete the rebased branch (locally)
git branch -d <feature branch>
# Push all changes to the remote repo
git push


# Another workflow (keeps history linear)
# - Fetches remote changes into origin/master
# - Rebase your own master changes on top of it.
#
git fetch
git rebase origin/master



# Example of a typical Github pull request
#
- Github repo > Fork;  creates a fork under your username
- Clone the fork (under your username)
- Create and checkout a new branch for your changes:
  git checkout -b my_new_branch
- Create your files
- Stage and commit your files:
  git add .
  git commit -m "New feature"
- Push your new local branch to the remote server
  git push -u origin my_new_branch
- Test/validate your changes
- Open a Pull request:
  > Your Github project repo > Pull request
    > Write description of your pull request
    > Double check the changes files and diffs
    > Create pull request
- In case of comments to your pull request:
  - Update your files
  - Stage and commit your files
    git add .
    git commit -m "Processed project comments and added them to new feature files"
  - Push your files again (will be added to your pull request automatically)
    git push

# Squashing changes via interactive rebase (in case of comment to your pull request)
#
- Do an interactive rebase:
  git rebase -i master
- This opens texteditor with a list of commits. The first word of each line contains a command:
    pick		Use this commit (default command)
    squash 		Use commit, but meld into previous commit
    fixup		Like squash, but discard this commit's log message
- Adapt the commands. Save file.
- Brings you in commit message editor. Adapt the commit message(s). Save file.
- Check the latest commit and status:
  - git show
  - git status
  - git log --graph --oneline --all
- Push the changes to the remote repo.
  If you use git push, this will fail, because the number of commits differs.
  Instead use a forced push to replace the remote commits by the squashed commit:
  - git push -file


# More info about merging pull requests
#
https://help.github.com/en/articles/about-pull-request-merges


# Code reviews
#
http://google.github.io/styleguide/
https://help.github.com/en/articles/about-pull-request-reviews
https://medium.com/osedea/the-perfect-code-review-process-845e6ba5c31
https://smartbear.com/learn/code-review/what-is-code-review/



Troubleshooting
===============

# Monitoring Tools
#
Process Monitor 				https://docs.microsoft.com/en-us/sysinternals/downloads/procmon
Perf analysis in 60s 			http://www.brendangregg.com/linuxperf.html
The USE Method 					http://brendangregg.com/usemethod.html
Activity Monitor in Mac: 		https://support.apple.com/nl-nl/guide/activity-monitor/welcome/mac
Performance Monitor on Windows 	https://www.windowscentral.com/how-use-performance-monitor-windows-10
Resource Monitor in Windows 	https://www.digitalcitizen.life/how-use-resource-monitor-windows-7
Process Explorer Windows 		https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer
Linux nice levels				https://www.reddit.com/r/linux/comments/d7hx2c/why_nice_levels_are_a_placebo_and_have_been_for_a/


# Logfiles Linux
/var/log/syslog
/var/log/syslog/.xsession-errors

# Logfiles MacOS
/Library/Logs

# Logfiles Windows
Via Event Viewer tool


# Performance MacOS
Activity monitor

# Performance Windows
Resource monitor
Performance monitor


# Trace system calls
# https://www.howtoforge.com/linux-strace-command/
#
strace ./myAmazingApp.py
strace -o output.strace ./myAmazingApp.py
	less output.strace
	shift-g 	# movees to end of file


# Trace system calls MacOS
dtruss


# Trace library calls
ltrace <executable ELF>


# Top processes
top

# Kill (e.g. hanging) process (gracefully)
kill -STOP <pid>

# Kill all httpd processes (gracefully)
killall -STOP httpd


# Top I/O processes
sudo iotop

# Statistics on I/O operations
iostat

# Statistics on virtual memory operations
vmstat


# Network usage on interfaces
iftop


# Apache benchmark to check slow web server
ab -n <#requests> <url>
ab -n 500 www.google.com



# Sync the contents of dir1 to dir2 on the same system, type:
# Source: https://www.digitalocean.com/community/tutorials/how-to-use-rsync-to-sync-local-and-remote-directories
#
# This is recursive option.
# Note the /
rsync -r dir1/ dir2

# Archive option. Syncs recursively and preserves symbolic links, special and device files,
# and file attributes. More commonly used than -r and is usually what you want to use.
# Note the /
rsync -a dir1/ dir2

# Always do a dry-run when using rsync by passing the -n or --dry-run options.
# The -v flag (for verbose) is also necessary to get the appropriate output
rsync -anv dir1/ dir2


# Syncing to a remote system
# (if you have SSH access to the remote machine and rsync installed on both sides)
# Sync/push the dir1 folder to a remote host (we want to transfer the actual directory, so we omit the trailing slash):
#
rsync -a ~/dir1 username@remote_host:destination_directory

This is called a “push” operation because it pushes a directory from the local system
to a remote system. The opposite operation is

# Sync/pull” a remote directory to the local system.
rsync -a username@remote_host:/home/username/dir1 place_to_sync_on_local_machine


# Limiting rsync bandwidth
rsync -bwlimit ...

# Trickle is a network bandwidth shaper tool
# For example limiting the download speed to 1024Kbps:
trickle -d 1024 wget -c <url>



# Set or get process I/O scheduling class and priority
#
# Sets process with PID 89 as an idle I/O process.
ionice -c 3 -p 89
# Runs 'bash' as a best-effort program with highest priority.
ionice -c 2 -n 0 bash
# Prints the class and priority of the processes with PID 89 and 91.
ionice -p 89 91


# Alter priority of running processes
# range -20 to 19
#    0: 	base scheduling priority
#   19: 	lowest, run only when nothing else wants to
#   20:		highes prio (to make things go very fast).
#
renice 19 <pid>

# Find the process ID of a running program
pidof bash
pidof sshd

for pid in $(pidof httpd); do renice -6 $pid; done


# Find location (directory) of a file
#
locate <file>
locate help-htdp.txt


Linux performance analysis in 60 secs (brendangregg):
- uptime
- sudo dmesg | tail
- vmstat 1
- mpstat -P all
- pidstat 1
- iostat -xz 1
- free -m
- sar -n DEV 1
- sar -n TCP,ETCP 1
- top


Profilers
C 		gprof
Python 	cProfile, pprofile3, memory_profiler




# Check real, user space and system time of an executed program
time ./myProgram.py


# Use top to show all running processes and their memory usage.
# VIRT, RES, SHR, MEM
# Shift-m to sort on memory columns
top


# pprofile3 outputting Callgrind Profile Format
pprofile -f callgrind -o cachegrind.out.results ./myProgram.py
pprofile --format callgrind --out cachegrind.out.results ./myProgram.py

# Callgrind format is implicitly enabled if --out basename starts with cachegrind.out.,
# so command can be simplified to:
pprofile --out cachegrind.out.results demo/threads.py

# Check results with graphical kcachegrind tool:
kcachegrind cachegrind.out.results



# Profile Size of Individual Objects
import sys
sys.getsizeof({})
sys.getsizeof([])
sys.getsizeof(set())



memory_profiler
---------------
https://www.pluralsight.com/blog/tutorials/how-to-profile-memory-usage-in-python

# Profile a Single Function or Method?
#
# Puttthe @profile decorator around any function or method
#
python -m memory_profiler <yourscript.py>



guppy - python2
---------------
# Profile an entire Application.
#
# To use guppy, drop something like this in your code.
#
from guppy import hpy

h = hpy()
print h.heap()


guppy - python3
---------------
https://github.com/zhuyifei1999/guppy3

# Create the session context:
from guppy import hpy
h=hpy()

#Show the reachable objects in the heap:
h.heap()

# Show the shortest paths from the root to the single largest object:
h.heap().byid[0].sp

# How to create and show a set of objects:
h.iso(1,[],{})


mprof
-----
# Show you memory usage over the lifetime of your application.
# Creates a graph of your script’s memory usage which you can view by running mprof plot (requires matplotlib)
#
mprof run <script> <script_args>



Threading and asyncio modules
-----------------------------
https://realpython.com/python-concurrency/
https://hackernoon.com/threaded-asynchronous-magic-and-how-to-wield-it-bba9ed602c32


Threading - concurrent.futures
------------------------------
- Multiprocess (ProcessPoolExecutor). Spawn multiple processes with its own Python interpreter. Bypasses Python’s Global Interpreter Lock (GIL). Best for CPU-bound tasks.
- Multithread (ThreadPoolExecutor). Uses multiple threads in the same process. Threads share the same interpreter and memory space. Best for I/O-heavy tasks. Threads are not interruptible/killable like processes are.


# https://www.digitalocean.com/community/tutorials/how-to-use-threadpoolexecutor-in-python-3
#
import requests
import concurrent.futures

def get_wiki_page_existence(wiki_page_url, timeout=10):
    response = requests.get(url=wiki_page_url, timeout=timeout)

    page_status = "unknown"
    if response.status_code == 200:
        page_status = "exists"
    elif response.status_code == 404:
        page_status = "does not exist"

    return wiki_page_url + " - " + page_status

wiki_page_urls = [
    "https://en.wikipedia.org/wiki/Ocean",
    "https://en.wikipedia.org/wiki/Island",
    "https://en.wikipedia.org/wiki/this_page_does_not_exist",
    "https://en.wikipedia.org/wiki/Shark",
]
with concurrent.futures.ThreadPoolExecutor() as executor:
    futures = []
    for url in wiki_page_urls:
        futures.append(
            executor.submit(
                get_wiki_page_existence, wiki_page_url=url, timeout=0.00001
            )
        )
    for future in concurrent.futures.as_completed(futures):
        try:
            print(future.result())
        except requests.ConnectTimeout:
            print("ConnectTimeout.")


# Alternative
executor = concurrent.futures.ThreadPoolExecutor()
executor.submit(get_wiki_page_existence, wiki_page_url=url, timeout=0.00001)
print("Wait for all threads to finish")
executor.shutdown()

# Alternative with ProcessPoolExecutor
executor = concurrent.futures.ProcessPoolExecutor()
executor.submit(get_wiki_page_existence, wiki_page_url=url, timeout=0.00001)
print("Wait for all processes to finish")
executor.shutdown()


Python concurrency:	https://realpython.com/python-concurrency/
Python asyncio: 	https://hackernoon.com/threaded-asynchronous-magic-and-how-to-wield-it-bba9ed602c32


---

#!/usr/bin/env python3
from multiprocessing import Pool

def run(task):
  # Do something with task here
    print("Handling {}".format(task))

if __name__ == "__main__":
  tasks = ['task1', 'task2', 'task3']
  # Create a pool of specific number of CPUs
  p = Pool(len(tasks))
  # Start each task within the pool
  p.map(run, tasks)


---


#!/usr/bin/env python3

import os
from multiprocessing import Pool
import subprocess


def run_rsync_dir(dir):
    print("Syncing {}".format(dir))
    src = '/data/prod/'
    dst = '/data/prod_backup'
    # subprocess.run(["rsync", "-av", "--dry-run", src, dst])
    subprocess.run(["rsync", "-arq", src, dst])


if __name__ == "__main__":

    path = '/data/prod'
    sync_dirs = []
    for (root,dir,files) in os.walk(path, topdown=True):
    	sync_dirs.append(root)

    p = Pool(len(sync_dirs))
    p.map(run_rsync_dir, sync_dirs)


sudo netstat -nlp | grep :80
/etc/nginx
/etc/nginx/sites.enabled
/etc/uwsgi
/etc/uwsgi/apps-enabled
sudo servuce uwsgi reload

System Log Linux 			https://www.fosslinux.com/8984/how-to-check-system-logs-on-linux-complete-usage-guide.htm
System Log on Windows 10 	https://www.digitalmastersmag.com/magazine/tip-of-the-day-how-to-find-crash-logs-on-windows-10/
System Log on a MacOS 		https://www.howtogeek.com/356942/how-to-view-the-system-log-on-a-mac/
System calls MacOS 			https://etcnotes.com/posts/system-call/



memtest86 and memtest86+		Test and stress test the random access memory of an x86 architecture system for errors
Valgrind 	(Linux, MacOS) 		Memory debugger, memory leak detection and profiling.
Dr. Memory 	(Linux, Windows) 	Memory debugger
pdb3 							Python Debugger

# Run Python debugger
pdb3 my_program <args>
	next
	continue
	print(var)

# Enabling Linux core dumps
ulimit -c unlimited
ulimit -S -c unlimited

# Disable core dumps
ulimit -c 0
ulimit -S -c 0

# Check core dump settings
ulimit -a


# Load core file in gdb debugger
ls -l core
gdb -c core <program>

	# Stacktrace/backtrace
	backtrace
	# Move to the calling function
	up
	# List more lines of code
	list
	# Print value of variable
	print i


# Dump files in octal and other formats
# /dev/random, /dev/urandom and /dev/arandom are special files that serve as pseudorandom number generators.
# -c characters
# -x hex
#
od -cx /dev/urandom


+++ check git bisect +++


SSH Access with PEM file
------------------------
download PEM key file
chmod 600 <keyfile>.pem
ssh -i <keyfile>.pem username@<IP Address>


